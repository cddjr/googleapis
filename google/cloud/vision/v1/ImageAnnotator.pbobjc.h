// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/vision/v1/image_annotator.proto

// This CPP symbol can be defined to use imports that match up to the framework
// imports needed when using CocoaPods.
#if !defined(GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS)
 #define GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS 0
#endif

#if GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS
 #import <Protobuf/GPBProtocolBuffers.h>
#else
 #import "GPBProtocolBuffers.h"
#endif

#if GOOGLE_PROTOBUF_OBJC_VERSION < 30002
#error This file was generated by a newer version of protoc which is incompatible with your Protocol Buffer library sources.
#endif
#if 30002 < GOOGLE_PROTOBUF_OBJC_MIN_SUPPORTED_VERSION
#error This file was generated by an older version of protoc which is incompatible with your Protocol Buffer library sources.
#endif

// @@protoc_insertion_point(imports)

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wdeprecated-declarations"

CF_EXTERN_C_BEGIN

@class GCVNAnnotateImageRequest;
@class GCVNAnnotateImageResponse;
@class GCVNAsyncAnnotateFileRequest;
@class GCVNAsyncAnnotateFileResponse;
@class GCVNBoundingPoly;
@class GCVNColorInfo;
@class GCVNCropHint;
@class GCVNCropHintsAnnotation;
@class GCVNCropHintsParams;
@class GCVNDominantColorsAnnotation;
@class GCVNEntityAnnotation;
@class GCVNFaceAnnotation;
@class GCVNFaceAnnotation_Landmark;
@class GCVNFeature;
@class GCVNGcsDestination;
@class GCVNGcsSource;
@class GCVNImage;
@class GCVNImageAnnotationContext;
@class GCVNImageContext;
@class GCVNImageProperties;
@class GCVNImageSource;
@class GCVNInputConfig;
@class GCVNLatLongRect;
@class GCVNLocalizedObjectAnnotation;
@class GCVNLocationInfo;
@class GCVNOutputConfig;
@class GCVNPosition;
@class GCVNProductSearchParams;
@class GCVNProductSearchResults;
@class GCVNProperty;
@class GCVNSafeSearchAnnotation;
@class GCVNTextAnnotation;
@class GCVNWebDetection;
@class GCVNWebDetectionParams;
@class GPBTimestamp;
@class GTPColor;
@class GTPLatLng;
@class Status;

NS_ASSUME_NONNULL_BEGIN

#pragma mark - Enum GCVNLikelihood

/**
 * A bucketized representation of likelihood, which is intended to give clients
 * highly stable results across model upgrades.
 **/
typedef GPB_ENUM(GCVNLikelihood) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  GCVNLikelihood_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Unknown likelihood. */
  GCVNLikelihood_Unknown = 0,

  /** It is very unlikely that the image belongs to the specified vertical. */
  GCVNLikelihood_VeryUnlikely = 1,

  /** It is unlikely that the image belongs to the specified vertical. */
  GCVNLikelihood_Unlikely = 2,

  /** It is possible that the image belongs to the specified vertical. */
  GCVNLikelihood_Possible = 3,

  /** It is likely that the image belongs to the specified vertical. */
  GCVNLikelihood_Likely = 4,

  /** It is very likely that the image belongs to the specified vertical. */
  GCVNLikelihood_VeryLikely = 5,
};

GPBEnumDescriptor *GCVNLikelihood_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL GCVNLikelihood_IsValidValue(int32_t value);

#pragma mark - Enum GCVNFeature_Type

/** Type of Google Cloud Vision API feature to be extracted. */
typedef GPB_ENUM(GCVNFeature_Type) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  GCVNFeature_Type_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Unspecified feature type. */
  GCVNFeature_Type_TypeUnspecified = 0,

  /** Run face detection. */
  GCVNFeature_Type_FaceDetection = 1,

  /** Run landmark detection. */
  GCVNFeature_Type_LandmarkDetection = 2,

  /** Run logo detection. */
  GCVNFeature_Type_LogoDetection = 3,

  /** Run label detection. */
  GCVNFeature_Type_LabelDetection = 4,

  /**
   * Run text detection / optical character recognition (OCR). Text detection
   * is optimized for areas of text within a larger image; if the image is
   * a document, use `DOCUMENT_TEXT_DETECTION` instead.
   **/
  GCVNFeature_Type_TextDetection = 5,

  /**
   * Run dense text document OCR. Takes precedence when both
   * `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.
   **/
  GCVNFeature_Type_DocumentTextDetection = 11,

  /**
   * Run Safe Search to detect potentially unsafe
   * or undesirable content.
   **/
  GCVNFeature_Type_SafeSearchDetection = 6,

  /**
   * Compute a set of image properties, such as the
   * image's dominant colors.
   **/
  GCVNFeature_Type_ImageProperties = 7,

  /** Run crop hints. */
  GCVNFeature_Type_CropHints = 9,

  /** Run web detection. */
  GCVNFeature_Type_WebDetection = 10,

  /** Run Product Search. */
  GCVNFeature_Type_ProductSearch = 12,

  /** Run localizer for object detection. */
  GCVNFeature_Type_ObjectLocalization = 19,
};

GPBEnumDescriptor *GCVNFeature_Type_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL GCVNFeature_Type_IsValidValue(int32_t value);

#pragma mark - Enum GCVNFaceAnnotation_Landmark_Type

/**
 * Face landmark (feature) type.
 * Left and right are defined from the vantage of the viewer of the image
 * without considering mirror projections typical of photos. So, `LEFT_EYE`,
 * typically, is the person's right eye.
 **/
typedef GPB_ENUM(GCVNFaceAnnotation_Landmark_Type) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  GCVNFaceAnnotation_Landmark_Type_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Unknown face landmark detected. Should not be filled. */
  GCVNFaceAnnotation_Landmark_Type_UnknownLandmark = 0,

  /** Left eye. */
  GCVNFaceAnnotation_Landmark_Type_LeftEye = 1,

  /** Right eye. */
  GCVNFaceAnnotation_Landmark_Type_RightEye = 2,

  /** Left of left eyebrow. */
  GCVNFaceAnnotation_Landmark_Type_LeftOfLeftEyebrow = 3,

  /** Right of left eyebrow. */
  GCVNFaceAnnotation_Landmark_Type_RightOfLeftEyebrow = 4,

  /** Left of right eyebrow. */
  GCVNFaceAnnotation_Landmark_Type_LeftOfRightEyebrow = 5,

  /** Right of right eyebrow. */
  GCVNFaceAnnotation_Landmark_Type_RightOfRightEyebrow = 6,

  /** Midpoint between eyes. */
  GCVNFaceAnnotation_Landmark_Type_MidpointBetweenEyes = 7,

  /** Nose tip. */
  GCVNFaceAnnotation_Landmark_Type_NoseTip = 8,

  /** Upper lip. */
  GCVNFaceAnnotation_Landmark_Type_UpperLip = 9,

  /** Lower lip. */
  GCVNFaceAnnotation_Landmark_Type_LowerLip = 10,

  /** Mouth left. */
  GCVNFaceAnnotation_Landmark_Type_MouthLeft = 11,

  /** Mouth right. */
  GCVNFaceAnnotation_Landmark_Type_MouthRight = 12,

  /** Mouth center. */
  GCVNFaceAnnotation_Landmark_Type_MouthCenter = 13,

  /** Nose, bottom right. */
  GCVNFaceAnnotation_Landmark_Type_NoseBottomRight = 14,

  /** Nose, bottom left. */
  GCVNFaceAnnotation_Landmark_Type_NoseBottomLeft = 15,

  /** Nose, bottom center. */
  GCVNFaceAnnotation_Landmark_Type_NoseBottomCenter = 16,

  /** Left eye, top boundary. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyeTopBoundary = 17,

  /** Left eye, right corner. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyeRightCorner = 18,

  /** Left eye, bottom boundary. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyeBottomBoundary = 19,

  /** Left eye, left corner. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyeLeftCorner = 20,

  /** Right eye, top boundary. */
  GCVNFaceAnnotation_Landmark_Type_RightEyeTopBoundary = 21,

  /** Right eye, right corner. */
  GCVNFaceAnnotation_Landmark_Type_RightEyeRightCorner = 22,

  /** Right eye, bottom boundary. */
  GCVNFaceAnnotation_Landmark_Type_RightEyeBottomBoundary = 23,

  /** Right eye, left corner. */
  GCVNFaceAnnotation_Landmark_Type_RightEyeLeftCorner = 24,

  /** Left eyebrow, upper midpoint. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyebrowUpperMidpoint = 25,

  /** Right eyebrow, upper midpoint. */
  GCVNFaceAnnotation_Landmark_Type_RightEyebrowUpperMidpoint = 26,

  /** Left ear tragion. */
  GCVNFaceAnnotation_Landmark_Type_LeftEarTragion = 27,

  /** Right ear tragion. */
  GCVNFaceAnnotation_Landmark_Type_RightEarTragion = 28,

  /** Left eye pupil. */
  GCVNFaceAnnotation_Landmark_Type_LeftEyePupil = 29,

  /** Right eye pupil. */
  GCVNFaceAnnotation_Landmark_Type_RightEyePupil = 30,

  /** Forehead glabella. */
  GCVNFaceAnnotation_Landmark_Type_ForeheadGlabella = 31,

  /** Chin gnathion. */
  GCVNFaceAnnotation_Landmark_Type_ChinGnathion = 32,

  /** Chin left gonion. */
  GCVNFaceAnnotation_Landmark_Type_ChinLeftGonion = 33,

  /** Chin right gonion. */
  GCVNFaceAnnotation_Landmark_Type_ChinRightGonion = 34,
};

GPBEnumDescriptor *GCVNFaceAnnotation_Landmark_Type_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL GCVNFaceAnnotation_Landmark_Type_IsValidValue(int32_t value);

#pragma mark - Enum GCVNOperationMetadata_State

/** Batch operation states. */
typedef GPB_ENUM(GCVNOperationMetadata_State) {
  /**
   * Value used if any message's field encounters a value that is not defined
   * by this enum. The message will also have C functions to get/set the rawValue
   * of the field.
   **/
  GCVNOperationMetadata_State_GPBUnrecognizedEnumeratorValue = kGPBUnrecognizedEnumeratorValue,
  /** Invalid. */
  GCVNOperationMetadata_State_StateUnspecified = 0,

  /** Request is received. */
  GCVNOperationMetadata_State_Created = 1,

  /** Request is actively being processed. */
  GCVNOperationMetadata_State_Running = 2,

  /** The batch processing is done. */
  GCVNOperationMetadata_State_Done = 3,

  /** The batch processing was cancelled. */
  GCVNOperationMetadata_State_Cancelled = 4,
};

GPBEnumDescriptor *GCVNOperationMetadata_State_EnumDescriptor(void);

/**
 * Checks to see if the given value is defined by the enum or was not known at
 * the time this source was generated.
 **/
BOOL GCVNOperationMetadata_State_IsValidValue(int32_t value);

#pragma mark - GCVNImageAnnotatorRoot

/**
 * Exposes the extension registry for this file.
 *
 * The base class provides:
 * @code
 *   + (GPBExtensionRegistry *)extensionRegistry;
 * @endcode
 * which is a @c GPBExtensionRegistry that includes all the extensions defined by
 * this file and all files that it depends on.
 **/
@interface GCVNImageAnnotatorRoot : GPBRootObject
@end

#pragma mark - GCVNFeature

typedef GPB_ENUM(GCVNFeature_FieldNumber) {
  GCVNFeature_FieldNumber_Type = 1,
  GCVNFeature_FieldNumber_MaxResults = 2,
  GCVNFeature_FieldNumber_Model = 3,
};

/**
 * The type of Google Cloud Vision API detection to perform, and the maximum
 * number of results to return for that type. Multiple `Feature` objects can
 * be specified in the `features` list.
 **/
@interface GCVNFeature : GPBMessage

/** The feature type. */
@property(nonatomic, readwrite) GCVNFeature_Type type;

/**
 * Maximum number of results of this type. Does not apply to
 * `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.
 **/
@property(nonatomic, readwrite) int32_t maxResults;

/**
 * Model to use for the feature.
 * Supported values: "builtin/stable" (the default if unset) and
 * "builtin/latest".
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *model;

@end

/**
 * Fetches the raw value of a @c GCVNFeature's @c type property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFeature_Type_RawValue(GCVNFeature *message);
/**
 * Sets the raw value of an @c GCVNFeature's @c type property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFeature_Type_RawValue(GCVNFeature *message, int32_t value);

#pragma mark - GCVNImageSource

typedef GPB_ENUM(GCVNImageSource_FieldNumber) {
  GCVNImageSource_FieldNumber_GcsImageUri = 1,
  GCVNImageSource_FieldNumber_ImageUri = 2,
};

/**
 * External image source (Google Cloud Storage or web URL image location).
 **/
@interface GCVNImageSource : GPBMessage

/**
 * **Use `image_uri` instead.**
 *
 * The Google Cloud Storage  URI of the form
 * `gs://bucket_name/object_name`. Object versioning is not supported. See
 * [Google Cloud Storage Request
 * URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *gcsImageUri;

/**
 * The URI of the source image. Can be either:
 *
 * 1. A Google Cloud Storage URI of the form
 *    `gs://bucket_name/object_name`. Object versioning is not supported. See
 *    [Google Cloud Storage Request
 *    URIs](https://cloud.google.com/storage/docs/reference-uris) for more
 *    info.
 *
 * 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from
 *    HTTP/HTTPS URLs, Google cannot guarantee that the request will be
 *    completed. Your request may fail if the specified host denies the
 *    request (e.g. due to request throttling or DOS prevention), or if Google
 *    throttles requests to the site for abuse prevention. You should not
 *    depend on externally-hosted images for production applications.
 *
 * When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
 * precedence.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *imageUri;

@end

#pragma mark - GCVNImage

typedef GPB_ENUM(GCVNImage_FieldNumber) {
  GCVNImage_FieldNumber_Content = 1,
  GCVNImage_FieldNumber_Source = 2,
};

/**
 * Client image to perform Google Cloud Vision API tasks over.
 **/
@interface GCVNImage : GPBMessage

/**
 * Image content, represented as a stream of bytes.
 * Note: As with all `bytes` fields, protobuffers use a pure binary
 * representation, whereas JSON representations use base64.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSData *content;

/**
 * Google Cloud Storage image location, or publicly-accessible image
 * URL. If both `content` and `source` are provided for an image, `content`
 * takes precedence and is used to perform the image annotation request.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNImageSource *source;
/** Test to see if @c source has been set. */
@property(nonatomic, readwrite) BOOL hasSource;

@end

#pragma mark - GCVNFaceAnnotation

typedef GPB_ENUM(GCVNFaceAnnotation_FieldNumber) {
  GCVNFaceAnnotation_FieldNumber_BoundingPoly = 1,
  GCVNFaceAnnotation_FieldNumber_FdBoundingPoly = 2,
  GCVNFaceAnnotation_FieldNumber_LandmarksArray = 3,
  GCVNFaceAnnotation_FieldNumber_RollAngle = 4,
  GCVNFaceAnnotation_FieldNumber_PanAngle = 5,
  GCVNFaceAnnotation_FieldNumber_TiltAngle = 6,
  GCVNFaceAnnotation_FieldNumber_DetectionConfidence = 7,
  GCVNFaceAnnotation_FieldNumber_LandmarkingConfidence = 8,
  GCVNFaceAnnotation_FieldNumber_JoyLikelihood = 9,
  GCVNFaceAnnotation_FieldNumber_SorrowLikelihood = 10,
  GCVNFaceAnnotation_FieldNumber_AngerLikelihood = 11,
  GCVNFaceAnnotation_FieldNumber_SurpriseLikelihood = 12,
  GCVNFaceAnnotation_FieldNumber_UnderExposedLikelihood = 13,
  GCVNFaceAnnotation_FieldNumber_BlurredLikelihood = 14,
  GCVNFaceAnnotation_FieldNumber_HeadwearLikelihood = 15,
};

/**
 * A face annotation object contains the results of face detection.
 **/
@interface GCVNFaceAnnotation : GPBMessage

/**
 * The bounding polygon around the face. The coordinates of the bounding box
 * are in the original image's scale, as returned in `ImageParams`.
 * The bounding box is computed to "frame" the face in accordance with human
 * expectations. It is based on the landmarker results.
 * Note that one or more x and/or y coordinates may not be generated in the
 * `BoundingPoly` (the polygon will be unbounded) if only a partial face
 * appears in the image to be annotated.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNBoundingPoly *boundingPoly;
/** Test to see if @c boundingPoly has been set. */
@property(nonatomic, readwrite) BOOL hasBoundingPoly;

/**
 * The `fd_bounding_poly` bounding polygon is tighter than the
 * `boundingPoly`, and encloses only the skin part of the face. Typically, it
 * is used to eliminate the face from any image analysis that detects the
 * "amount of skin" visible in an image. It is not based on the
 * landmarker results, only on the initial face detection, hence
 * the <code>fd</code> (face detection) prefix.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNBoundingPoly *fdBoundingPoly;
/** Test to see if @c fdBoundingPoly has been set. */
@property(nonatomic, readwrite) BOOL hasFdBoundingPoly;

/** Detected face landmarks. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNFaceAnnotation_Landmark*> *landmarksArray;
/** The number of items in @c landmarksArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger landmarksArray_Count;

/**
 * Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
 * of the face relative to the image vertical about the axis perpendicular to
 * the face. Range [-180,180].
 **/
@property(nonatomic, readwrite) float rollAngle;

/**
 * Yaw angle, which indicates the leftward/rightward angle that the face is
 * pointing relative to the vertical plane perpendicular to the image. Range
 * [-180,180].
 **/
@property(nonatomic, readwrite) float panAngle;

/**
 * Pitch angle, which indicates the upwards/downwards angle that the face is
 * pointing relative to the image's horizontal plane. Range [-180,180].
 **/
@property(nonatomic, readwrite) float tiltAngle;

/** Detection confidence. Range [0, 1]. */
@property(nonatomic, readwrite) float detectionConfidence;

/** Face landmarking confidence. Range [0, 1]. */
@property(nonatomic, readwrite) float landmarkingConfidence;

/** Joy likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood joyLikelihood;

/** Sorrow likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood sorrowLikelihood;

/** Anger likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood angerLikelihood;

/** Surprise likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood surpriseLikelihood;

/** Under-exposed likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood underExposedLikelihood;

/** Blurred likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood blurredLikelihood;

/** Headwear likelihood. */
@property(nonatomic, readwrite) GCVNLikelihood headwearLikelihood;

@end

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c joyLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_JoyLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c joyLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_JoyLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c sorrowLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_SorrowLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c sorrowLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_SorrowLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c angerLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_AngerLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c angerLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_AngerLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c surpriseLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_SurpriseLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c surpriseLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_SurpriseLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c underExposedLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_UnderExposedLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c underExposedLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_UnderExposedLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c blurredLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_BlurredLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c blurredLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_BlurredLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation's @c headwearLikelihood property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_HeadwearLikelihood_RawValue(GCVNFaceAnnotation *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation's @c headwearLikelihood property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_HeadwearLikelihood_RawValue(GCVNFaceAnnotation *message, int32_t value);

#pragma mark - GCVNFaceAnnotation_Landmark

typedef GPB_ENUM(GCVNFaceAnnotation_Landmark_FieldNumber) {
  GCVNFaceAnnotation_Landmark_FieldNumber_Type = 3,
  GCVNFaceAnnotation_Landmark_FieldNumber_Position = 4,
};

/**
 * A face-specific landmark (for example, a face feature).
 **/
@interface GCVNFaceAnnotation_Landmark : GPBMessage

/** Face landmark type. */
@property(nonatomic, readwrite) GCVNFaceAnnotation_Landmark_Type type;

/** Face landmark position. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNPosition *position;
/** Test to see if @c position has been set. */
@property(nonatomic, readwrite) BOOL hasPosition;

@end

/**
 * Fetches the raw value of a @c GCVNFaceAnnotation_Landmark's @c type property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNFaceAnnotation_Landmark_Type_RawValue(GCVNFaceAnnotation_Landmark *message);
/**
 * Sets the raw value of an @c GCVNFaceAnnotation_Landmark's @c type property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNFaceAnnotation_Landmark_Type_RawValue(GCVNFaceAnnotation_Landmark *message, int32_t value);

#pragma mark - GCVNLocationInfo

typedef GPB_ENUM(GCVNLocationInfo_FieldNumber) {
  GCVNLocationInfo_FieldNumber_LatLng = 1,
};

/**
 * Detected entity location information.
 **/
@interface GCVNLocationInfo : GPBMessage

/** lat/long location coordinates. */
@property(nonatomic, readwrite, strong, null_resettable) GTPLatLng *latLng;
/** Test to see if @c latLng has been set. */
@property(nonatomic, readwrite) BOOL hasLatLng;

@end

#pragma mark - GCVNProperty

typedef GPB_ENUM(GCVNProperty_FieldNumber) {
  GCVNProperty_FieldNumber_Name = 1,
  GCVNProperty_FieldNumber_Value = 2,
  GCVNProperty_FieldNumber_Uint64Value = 3,
};

/**
 * A `Property` consists of a user-supplied name/value pair.
 **/
@interface GCVNProperty : GPBMessage

/** Name of the property. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *name;

/** Value of the property. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *value;

/** Value of numeric properties. */
@property(nonatomic, readwrite) uint64_t uint64Value;

@end

#pragma mark - GCVNEntityAnnotation

typedef GPB_ENUM(GCVNEntityAnnotation_FieldNumber) {
  GCVNEntityAnnotation_FieldNumber_Mid = 1,
  GCVNEntityAnnotation_FieldNumber_Locale = 2,
  GCVNEntityAnnotation_FieldNumber_Description_p = 3,
  GCVNEntityAnnotation_FieldNumber_Score = 4,
  GCVNEntityAnnotation_FieldNumber_Confidence = 5,
  GCVNEntityAnnotation_FieldNumber_Topicality = 6,
  GCVNEntityAnnotation_FieldNumber_BoundingPoly = 7,
  GCVNEntityAnnotation_FieldNumber_LocationsArray = 8,
  GCVNEntityAnnotation_FieldNumber_PropertiesArray = 9,
};

/**
 * Set of detected entity features.
 **/
@interface GCVNEntityAnnotation : GPBMessage

/**
 * Opaque entity ID. Some IDs may be available in
 * [Google Knowledge Graph Search
 * API](https://developers.google.com/knowledge-graph/).
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *mid;

/**
 * The language code for the locale in which the entity textual
 * `description` is expressed.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *locale;

/** Entity textual description, expressed in its `locale` language. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *description_p;

/** Overall score of the result. Range [0, 1]. */
@property(nonatomic, readwrite) float score;

/**
 * **Deprecated. Use `score` instead.**
 * The accuracy of the entity detection in an image.
 * For example, for an image in which the "Eiffel Tower" entity is detected,
 * this field represents the confidence that there is a tower in the query
 * image. Range [0, 1].
 **/
@property(nonatomic, readwrite) float confidence DEPRECATED_ATTRIBUTE;

/**
 * The relevancy of the ICA (Image Content Annotation) label to the
 * image. For example, the relevancy of "tower" is likely higher to an image
 * containing the detected "Eiffel Tower" than to an image containing a
 * detected distant towering building, even though the confidence that
 * there is a tower in each image may be the same. Range [0, 1].
 **/
@property(nonatomic, readwrite) float topicality;

/**
 * Image region to which this entity belongs. Not produced
 * for `LABEL_DETECTION` features.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNBoundingPoly *boundingPoly;
/** Test to see if @c boundingPoly has been set. */
@property(nonatomic, readwrite) BOOL hasBoundingPoly;

/**
 * The location information for the detected entity. Multiple
 * `LocationInfo` elements can be present because one location may
 * indicate the location of the scene in the image, and another location
 * may indicate the location of the place where the image was taken.
 * Location information is usually present for landmarks.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNLocationInfo*> *locationsArray;
/** The number of items in @c locationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger locationsArray_Count;

/**
 * Some entities may have optional user-supplied `Property` (name/value)
 * fields, such a score or string that qualifies the entity.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNProperty*> *propertiesArray;
/** The number of items in @c propertiesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger propertiesArray_Count;

@end

#pragma mark - GCVNLocalizedObjectAnnotation

typedef GPB_ENUM(GCVNLocalizedObjectAnnotation_FieldNumber) {
  GCVNLocalizedObjectAnnotation_FieldNumber_Mid = 1,
  GCVNLocalizedObjectAnnotation_FieldNumber_LanguageCode = 2,
  GCVNLocalizedObjectAnnotation_FieldNumber_Name = 3,
  GCVNLocalizedObjectAnnotation_FieldNumber_Score = 4,
  GCVNLocalizedObjectAnnotation_FieldNumber_BoundingPoly = 5,
};

/**
 * Set of detected objects with bounding boxes.
 **/
@interface GCVNLocalizedObjectAnnotation : GPBMessage

/** Object ID that should align with EntityAnnotation mid. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *mid;

/**
 * The BCP-47 language code, such as "en-US" or "sr-Latn". For more
 * information, see
 * http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *languageCode;

/** Object name, expressed in its `language_code` language. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *name;

/** Score of the result. Range [0, 1]. */
@property(nonatomic, readwrite) float score;

/** Image region to which this object belongs. This must be populated. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNBoundingPoly *boundingPoly;
/** Test to see if @c boundingPoly has been set. */
@property(nonatomic, readwrite) BOOL hasBoundingPoly;

@end

#pragma mark - GCVNSafeSearchAnnotation

typedef GPB_ENUM(GCVNSafeSearchAnnotation_FieldNumber) {
  GCVNSafeSearchAnnotation_FieldNumber_Adult = 1,
  GCVNSafeSearchAnnotation_FieldNumber_Spoof = 2,
  GCVNSafeSearchAnnotation_FieldNumber_Medical = 3,
  GCVNSafeSearchAnnotation_FieldNumber_Violence = 4,
  GCVNSafeSearchAnnotation_FieldNumber_Racy = 9,
};

/**
 * Set of features pertaining to the image, computed by computer vision
 * methods over safe-search verticals (for example, adult, spoof, medical,
 * violence).
 **/
@interface GCVNSafeSearchAnnotation : GPBMessage

/**
 * Represents the adult content likelihood for the image. Adult content may
 * contain elements such as nudity, pornographic images or cartoons, or
 * sexual activities.
 **/
@property(nonatomic, readwrite) GCVNLikelihood adult;

/**
 * Spoof likelihood. The likelihood that an modification
 * was made to the image's canonical version to make it appear
 * funny or offensive.
 **/
@property(nonatomic, readwrite) GCVNLikelihood spoof;

/** Likelihood that this is a medical image. */
@property(nonatomic, readwrite) GCVNLikelihood medical;

/** Likelihood that this image contains violent content. */
@property(nonatomic, readwrite) GCVNLikelihood violence;

/**
 * Likelihood that the request image contains racy content. Racy content may
 * include (but is not limited to) skimpy or sheer clothing, strategically
 * covered nudity, lewd or provocative poses, or close-ups of sensitive
 * body areas.
 **/
@property(nonatomic, readwrite) GCVNLikelihood racy;

@end

/**
 * Fetches the raw value of a @c GCVNSafeSearchAnnotation's @c adult property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNSafeSearchAnnotation_Adult_RawValue(GCVNSafeSearchAnnotation *message);
/**
 * Sets the raw value of an @c GCVNSafeSearchAnnotation's @c adult property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNSafeSearchAnnotation_Adult_RawValue(GCVNSafeSearchAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNSafeSearchAnnotation's @c spoof property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNSafeSearchAnnotation_Spoof_RawValue(GCVNSafeSearchAnnotation *message);
/**
 * Sets the raw value of an @c GCVNSafeSearchAnnotation's @c spoof property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNSafeSearchAnnotation_Spoof_RawValue(GCVNSafeSearchAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNSafeSearchAnnotation's @c medical property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNSafeSearchAnnotation_Medical_RawValue(GCVNSafeSearchAnnotation *message);
/**
 * Sets the raw value of an @c GCVNSafeSearchAnnotation's @c medical property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNSafeSearchAnnotation_Medical_RawValue(GCVNSafeSearchAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNSafeSearchAnnotation's @c violence property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNSafeSearchAnnotation_Violence_RawValue(GCVNSafeSearchAnnotation *message);
/**
 * Sets the raw value of an @c GCVNSafeSearchAnnotation's @c violence property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNSafeSearchAnnotation_Violence_RawValue(GCVNSafeSearchAnnotation *message, int32_t value);

/**
 * Fetches the raw value of a @c GCVNSafeSearchAnnotation's @c racy property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNSafeSearchAnnotation_Racy_RawValue(GCVNSafeSearchAnnotation *message);
/**
 * Sets the raw value of an @c GCVNSafeSearchAnnotation's @c racy property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNSafeSearchAnnotation_Racy_RawValue(GCVNSafeSearchAnnotation *message, int32_t value);

#pragma mark - GCVNLatLongRect

typedef GPB_ENUM(GCVNLatLongRect_FieldNumber) {
  GCVNLatLongRect_FieldNumber_MinLatLng = 1,
  GCVNLatLongRect_FieldNumber_MaxLatLng = 2,
};

/**
 * Rectangle determined by min and max `LatLng` pairs.
 **/
@interface GCVNLatLongRect : GPBMessage

/** Min lat/long pair. */
@property(nonatomic, readwrite, strong, null_resettable) GTPLatLng *minLatLng;
/** Test to see if @c minLatLng has been set. */
@property(nonatomic, readwrite) BOOL hasMinLatLng;

/** Max lat/long pair. */
@property(nonatomic, readwrite, strong, null_resettable) GTPLatLng *maxLatLng;
/** Test to see if @c maxLatLng has been set. */
@property(nonatomic, readwrite) BOOL hasMaxLatLng;

@end

#pragma mark - GCVNColorInfo

typedef GPB_ENUM(GCVNColorInfo_FieldNumber) {
  GCVNColorInfo_FieldNumber_Color = 1,
  GCVNColorInfo_FieldNumber_Score = 2,
  GCVNColorInfo_FieldNumber_PixelFraction = 3,
};

/**
 * Color information consists of RGB channels, score, and the fraction of
 * the image that the color occupies in the image.
 **/
@interface GCVNColorInfo : GPBMessage

/** RGB components of the color. */
@property(nonatomic, readwrite, strong, null_resettable) GTPColor *color;
/** Test to see if @c color has been set. */
@property(nonatomic, readwrite) BOOL hasColor;

/** Image-specific score for this color. Value in range [0, 1]. */
@property(nonatomic, readwrite) float score;

/**
 * The fraction of pixels the color occupies in the image.
 * Value in range [0, 1].
 **/
@property(nonatomic, readwrite) float pixelFraction;

@end

#pragma mark - GCVNDominantColorsAnnotation

typedef GPB_ENUM(GCVNDominantColorsAnnotation_FieldNumber) {
  GCVNDominantColorsAnnotation_FieldNumber_ColorsArray = 1,
};

/**
 * Set of dominant colors and their corresponding scores.
 **/
@interface GCVNDominantColorsAnnotation : GPBMessage

/** RGB color values with their score and pixel fraction. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNColorInfo*> *colorsArray;
/** The number of items in @c colorsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger colorsArray_Count;

@end

#pragma mark - GCVNImageProperties

typedef GPB_ENUM(GCVNImageProperties_FieldNumber) {
  GCVNImageProperties_FieldNumber_DominantColors = 1,
};

/**
 * Stores image properties, such as dominant colors.
 **/
@interface GCVNImageProperties : GPBMessage

/** If present, dominant colors completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNDominantColorsAnnotation *dominantColors;
/** Test to see if @c dominantColors has been set. */
@property(nonatomic, readwrite) BOOL hasDominantColors;

@end

#pragma mark - GCVNCropHint

typedef GPB_ENUM(GCVNCropHint_FieldNumber) {
  GCVNCropHint_FieldNumber_BoundingPoly = 1,
  GCVNCropHint_FieldNumber_Confidence = 2,
  GCVNCropHint_FieldNumber_ImportanceFraction = 3,
};

/**
 * Single crop hint that is used to generate a new crop when serving an image.
 **/
@interface GCVNCropHint : GPBMessage

/**
 * The bounding polygon for the crop region. The coordinates of the bounding
 * box are in the original image's scale, as returned in `ImageParams`.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNBoundingPoly *boundingPoly;
/** Test to see if @c boundingPoly has been set. */
@property(nonatomic, readwrite) BOOL hasBoundingPoly;

/** Confidence of this being a salient region.  Range [0, 1]. */
@property(nonatomic, readwrite) float confidence;

/**
 * Fraction of importance of this salient region with respect to the original
 * image.
 **/
@property(nonatomic, readwrite) float importanceFraction;

@end

#pragma mark - GCVNCropHintsAnnotation

typedef GPB_ENUM(GCVNCropHintsAnnotation_FieldNumber) {
  GCVNCropHintsAnnotation_FieldNumber_CropHintsArray = 1,
};

/**
 * Set of crop hints that are used to generate new crops when serving images.
 **/
@interface GCVNCropHintsAnnotation : GPBMessage

/** Crop hint results. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNCropHint*> *cropHintsArray;
/** The number of items in @c cropHintsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger cropHintsArray_Count;

@end

#pragma mark - GCVNCropHintsParams

typedef GPB_ENUM(GCVNCropHintsParams_FieldNumber) {
  GCVNCropHintsParams_FieldNumber_AspectRatiosArray = 1,
};

/**
 * Parameters for crop hints annotation request.
 **/
@interface GCVNCropHintsParams : GPBMessage

/**
 * Aspect ratios in floats, representing the ratio of the width to the height
 * of the image. For example, if the desired aspect ratio is 4/3, the
 * corresponding float value should be 1.33333.  If not specified, the
 * best possible crop is returned. The number of provided aspect ratios is
 * limited to a maximum of 16; any aspect ratios provided after the 16th are
 * ignored.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GPBFloatArray *aspectRatiosArray;
/** The number of items in @c aspectRatiosArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger aspectRatiosArray_Count;

@end

#pragma mark - GCVNWebDetectionParams

typedef GPB_ENUM(GCVNWebDetectionParams_FieldNumber) {
  GCVNWebDetectionParams_FieldNumber_IncludeGeoResults = 2,
};

/**
 * Parameters for web detection request.
 **/
@interface GCVNWebDetectionParams : GPBMessage

/** Whether to include results derived from the geo information in the image. */
@property(nonatomic, readwrite) BOOL includeGeoResults;

@end

#pragma mark - GCVNImageContext

typedef GPB_ENUM(GCVNImageContext_FieldNumber) {
  GCVNImageContext_FieldNumber_LatLongRect = 1,
  GCVNImageContext_FieldNumber_LanguageHintsArray = 2,
  GCVNImageContext_FieldNumber_CropHintsParams = 4,
  GCVNImageContext_FieldNumber_ProductSearchParams = 5,
  GCVNImageContext_FieldNumber_WebDetectionParams = 6,
};

/**
 * Image context and/or feature-specific parameters.
 **/
@interface GCVNImageContext : GPBMessage

/** Not used. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNLatLongRect *latLongRect;
/** Test to see if @c latLongRect has been set. */
@property(nonatomic, readwrite) BOOL hasLatLongRect;

/**
 * List of languages to use for TEXT_DETECTION. In most cases, an empty value
 * yields the best results since it enables automatic language detection. For
 * languages based on the Latin alphabet, setting `language_hints` is not
 * needed. In rare cases, when the language of the text in the image is known,
 * setting a hint will help get better results (although it will be a
 * significant hindrance if the hint is wrong). Text detection returns an
 * error if one or more of the specified languages is not one of the
 * [supported languages](/vision/docs/languages).
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<NSString*> *languageHintsArray;
/** The number of items in @c languageHintsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger languageHintsArray_Count;

/** Parameters for crop hints annotation request. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNCropHintsParams *cropHintsParams;
/** Test to see if @c cropHintsParams has been set. */
@property(nonatomic, readwrite) BOOL hasCropHintsParams;

/** Parameters for product search. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNProductSearchParams *productSearchParams;
/** Test to see if @c productSearchParams has been set. */
@property(nonatomic, readwrite) BOOL hasProductSearchParams;

/** Parameters for web detection. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNWebDetectionParams *webDetectionParams;
/** Test to see if @c webDetectionParams has been set. */
@property(nonatomic, readwrite) BOOL hasWebDetectionParams;

@end

#pragma mark - GCVNAnnotateImageRequest

typedef GPB_ENUM(GCVNAnnotateImageRequest_FieldNumber) {
  GCVNAnnotateImageRequest_FieldNumber_Image = 1,
  GCVNAnnotateImageRequest_FieldNumber_FeaturesArray = 2,
  GCVNAnnotateImageRequest_FieldNumber_ImageContext = 3,
};

/**
 * Request for performing Google Cloud Vision API tasks over a user-provided
 * image, with user-requested features.
 **/
@interface GCVNAnnotateImageRequest : GPBMessage

/** The image to be processed. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNImage *image;
/** Test to see if @c image has been set. */
@property(nonatomic, readwrite) BOOL hasImage;

/** Requested features. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNFeature*> *featuresArray;
/** The number of items in @c featuresArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger featuresArray_Count;

/** Additional context that may accompany the image. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNImageContext *imageContext;
/** Test to see if @c imageContext has been set. */
@property(nonatomic, readwrite) BOOL hasImageContext;

@end

#pragma mark - GCVNImageAnnotationContext

typedef GPB_ENUM(GCVNImageAnnotationContext_FieldNumber) {
  GCVNImageAnnotationContext_FieldNumber_Uri = 1,
  GCVNImageAnnotationContext_FieldNumber_PageNumber = 2,
};

/**
 * If an image was produced from a file (e.g. a PDF), this message gives
 * information about the source of that image.
 **/
@interface GCVNImageAnnotationContext : GPBMessage

/** The URI of the file used to produce the image. */
@property(nonatomic, readwrite, copy, null_resettable) NSString *uri;

/**
 * If the file was a PDF or TIFF, this field gives the page number within
 * the file used to produce the image.
 **/
@property(nonatomic, readwrite) int32_t pageNumber;

@end

#pragma mark - GCVNAnnotateImageResponse

typedef GPB_ENUM(GCVNAnnotateImageResponse_FieldNumber) {
  GCVNAnnotateImageResponse_FieldNumber_FaceAnnotationsArray = 1,
  GCVNAnnotateImageResponse_FieldNumber_LandmarkAnnotationsArray = 2,
  GCVNAnnotateImageResponse_FieldNumber_LogoAnnotationsArray = 3,
  GCVNAnnotateImageResponse_FieldNumber_LabelAnnotationsArray = 4,
  GCVNAnnotateImageResponse_FieldNumber_TextAnnotationsArray = 5,
  GCVNAnnotateImageResponse_FieldNumber_SafeSearchAnnotation = 6,
  GCVNAnnotateImageResponse_FieldNumber_ImagePropertiesAnnotation = 8,
  GCVNAnnotateImageResponse_FieldNumber_Error = 9,
  GCVNAnnotateImageResponse_FieldNumber_CropHintsAnnotation = 11,
  GCVNAnnotateImageResponse_FieldNumber_FullTextAnnotation = 12,
  GCVNAnnotateImageResponse_FieldNumber_WebDetection = 13,
  GCVNAnnotateImageResponse_FieldNumber_ProductSearchResults = 14,
  GCVNAnnotateImageResponse_FieldNumber_Context = 21,
  GCVNAnnotateImageResponse_FieldNumber_LocalizedObjectAnnotationsArray = 22,
};

/**
 * Response to an image annotation request.
 **/
@interface GCVNAnnotateImageResponse : GPBMessage

/** If present, face detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNFaceAnnotation*> *faceAnnotationsArray;
/** The number of items in @c faceAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger faceAnnotationsArray_Count;

/** If present, landmark detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNEntityAnnotation*> *landmarkAnnotationsArray;
/** The number of items in @c landmarkAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger landmarkAnnotationsArray_Count;

/** If present, logo detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNEntityAnnotation*> *logoAnnotationsArray;
/** The number of items in @c logoAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger logoAnnotationsArray_Count;

/** If present, label detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNEntityAnnotation*> *labelAnnotationsArray;
/** The number of items in @c labelAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger labelAnnotationsArray_Count;

/**
 * If present, localized object detection has completed successfully.
 * This will be sorted descending by confidence score.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNLocalizedObjectAnnotation*> *localizedObjectAnnotationsArray;
/** The number of items in @c localizedObjectAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger localizedObjectAnnotationsArray_Count;

/** If present, text (OCR) detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNEntityAnnotation*> *textAnnotationsArray;
/** The number of items in @c textAnnotationsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger textAnnotationsArray_Count;

/**
 * If present, text (OCR) detection or document (OCR) text detection has
 * completed successfully.
 * This annotation provides the structural hierarchy for the OCR detected
 * text.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNTextAnnotation *fullTextAnnotation;
/** Test to see if @c fullTextAnnotation has been set. */
@property(nonatomic, readwrite) BOOL hasFullTextAnnotation;

/** If present, safe-search annotation has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNSafeSearchAnnotation *safeSearchAnnotation;
/** Test to see if @c safeSearchAnnotation has been set. */
@property(nonatomic, readwrite) BOOL hasSafeSearchAnnotation;

/** If present, image properties were extracted successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNImageProperties *imagePropertiesAnnotation;
/** Test to see if @c imagePropertiesAnnotation has been set. */
@property(nonatomic, readwrite) BOOL hasImagePropertiesAnnotation;

/** If present, crop hints have completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNCropHintsAnnotation *cropHintsAnnotation;
/** Test to see if @c cropHintsAnnotation has been set. */
@property(nonatomic, readwrite) BOOL hasCropHintsAnnotation;

/** If present, web detection has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNWebDetection *webDetection;
/** Test to see if @c webDetection has been set. */
@property(nonatomic, readwrite) BOOL hasWebDetection;

/** If present, product search has completed successfully. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNProductSearchResults *productSearchResults;
/** Test to see if @c productSearchResults has been set. */
@property(nonatomic, readwrite) BOOL hasProductSearchResults;

/**
 * If set, represents the error message for the operation.
 * Note that filled-in image annotations are guaranteed to be
 * correct, even when `error` is set.
 **/
@property(nonatomic, readwrite, strong, null_resettable) Status *error;
/** Test to see if @c error has been set. */
@property(nonatomic, readwrite) BOOL hasError;

/**
 * If present, contextual information is needed to understand where this image
 * comes from.
 **/
@property(nonatomic, readwrite, strong, null_resettable) GCVNImageAnnotationContext *context;
/** Test to see if @c context has been set. */
@property(nonatomic, readwrite) BOOL hasContext;

@end

#pragma mark - GCVNAnnotateFileResponse

typedef GPB_ENUM(GCVNAnnotateFileResponse_FieldNumber) {
  GCVNAnnotateFileResponse_FieldNumber_InputConfig = 1,
  GCVNAnnotateFileResponse_FieldNumber_ResponsesArray = 2,
};

/**
 * Response to a single file annotation request. A file may contain one or more
 * images, which individually have their own responses.
 **/
@interface GCVNAnnotateFileResponse : GPBMessage

/** Information about the file for which this response is generated. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNInputConfig *inputConfig;
/** Test to see if @c inputConfig has been set. */
@property(nonatomic, readwrite) BOOL hasInputConfig;

/** Individual responses to images found within the file. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNAnnotateImageResponse*> *responsesArray;
/** The number of items in @c responsesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger responsesArray_Count;

@end

#pragma mark - GCVNBatchAnnotateImagesRequest

typedef GPB_ENUM(GCVNBatchAnnotateImagesRequest_FieldNumber) {
  GCVNBatchAnnotateImagesRequest_FieldNumber_RequestsArray = 1,
};

/**
 * Multiple image annotation requests are batched into a single service call.
 **/
@interface GCVNBatchAnnotateImagesRequest : GPBMessage

/** Individual image annotation requests for this batch. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNAnnotateImageRequest*> *requestsArray;
/** The number of items in @c requestsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger requestsArray_Count;

@end

#pragma mark - GCVNBatchAnnotateImagesResponse

typedef GPB_ENUM(GCVNBatchAnnotateImagesResponse_FieldNumber) {
  GCVNBatchAnnotateImagesResponse_FieldNumber_ResponsesArray = 1,
};

/**
 * Response to a batch image annotation request.
 **/
@interface GCVNBatchAnnotateImagesResponse : GPBMessage

/** Individual responses to image annotation requests within the batch. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNAnnotateImageResponse*> *responsesArray;
/** The number of items in @c responsesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger responsesArray_Count;

@end

#pragma mark - GCVNAsyncAnnotateFileRequest

typedef GPB_ENUM(GCVNAsyncAnnotateFileRequest_FieldNumber) {
  GCVNAsyncAnnotateFileRequest_FieldNumber_InputConfig = 1,
  GCVNAsyncAnnotateFileRequest_FieldNumber_FeaturesArray = 2,
  GCVNAsyncAnnotateFileRequest_FieldNumber_ImageContext = 3,
  GCVNAsyncAnnotateFileRequest_FieldNumber_OutputConfig = 4,
};

/**
 * An offline file annotation request.
 **/
@interface GCVNAsyncAnnotateFileRequest : GPBMessage

/** Required. Information about the input file. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNInputConfig *inputConfig;
/** Test to see if @c inputConfig has been set. */
@property(nonatomic, readwrite) BOOL hasInputConfig;

/** Required. Requested features. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNFeature*> *featuresArray;
/** The number of items in @c featuresArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger featuresArray_Count;

/** Additional context that may accompany the image(s) in the file. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNImageContext *imageContext;
/** Test to see if @c imageContext has been set. */
@property(nonatomic, readwrite) BOOL hasImageContext;

/** Required. The desired output location and metadata (e.g. format). */
@property(nonatomic, readwrite, strong, null_resettable) GCVNOutputConfig *outputConfig;
/** Test to see if @c outputConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputConfig;

@end

#pragma mark - GCVNAsyncAnnotateFileResponse

typedef GPB_ENUM(GCVNAsyncAnnotateFileResponse_FieldNumber) {
  GCVNAsyncAnnotateFileResponse_FieldNumber_OutputConfig = 1,
};

/**
 * The response for a single offline file annotation request.
 **/
@interface GCVNAsyncAnnotateFileResponse : GPBMessage

/** The output location and metadata from AsyncAnnotateFileRequest. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNOutputConfig *outputConfig;
/** Test to see if @c outputConfig has been set. */
@property(nonatomic, readwrite) BOOL hasOutputConfig;

@end

#pragma mark - GCVNAsyncBatchAnnotateFilesRequest

typedef GPB_ENUM(GCVNAsyncBatchAnnotateFilesRequest_FieldNumber) {
  GCVNAsyncBatchAnnotateFilesRequest_FieldNumber_RequestsArray = 1,
};

/**
 * Multiple async file annotation requests are batched into a single service
 * call.
 **/
@interface GCVNAsyncBatchAnnotateFilesRequest : GPBMessage

/** Individual async file annotation requests for this batch. */
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNAsyncAnnotateFileRequest*> *requestsArray;
/** The number of items in @c requestsArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger requestsArray_Count;

@end

#pragma mark - GCVNAsyncBatchAnnotateFilesResponse

typedef GPB_ENUM(GCVNAsyncBatchAnnotateFilesResponse_FieldNumber) {
  GCVNAsyncBatchAnnotateFilesResponse_FieldNumber_ResponsesArray = 1,
};

/**
 * Response to an async batch file annotation request.
 **/
@interface GCVNAsyncBatchAnnotateFilesResponse : GPBMessage

/**
 * The list of file annotation responses, one for each request in
 * AsyncBatchAnnotateFilesRequest.
 **/
@property(nonatomic, readwrite, strong, null_resettable) NSMutableArray<GCVNAsyncAnnotateFileResponse*> *responsesArray;
/** The number of items in @c responsesArray without causing the array to be created. */
@property(nonatomic, readonly) NSUInteger responsesArray_Count;

@end

#pragma mark - GCVNInputConfig

typedef GPB_ENUM(GCVNInputConfig_FieldNumber) {
  GCVNInputConfig_FieldNumber_GcsSource = 1,
  GCVNInputConfig_FieldNumber_MimeType = 2,
};

/**
 * The desired input location and metadata.
 **/
@interface GCVNInputConfig : GPBMessage

/** The Google Cloud Storage location to read the input from. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNGcsSource *gcsSource;
/** Test to see if @c gcsSource has been set. */
@property(nonatomic, readwrite) BOOL hasGcsSource;

/**
 * The type of the file. Currently only "application/pdf" and "image/tiff"
 * are supported. Wildcards are not supported.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *mimeType;

@end

#pragma mark - GCVNOutputConfig

typedef GPB_ENUM(GCVNOutputConfig_FieldNumber) {
  GCVNOutputConfig_FieldNumber_GcsDestination = 1,
  GCVNOutputConfig_FieldNumber_BatchSize = 2,
};

/**
 * The desired output location and metadata.
 **/
@interface GCVNOutputConfig : GPBMessage

/** The Google Cloud Storage location to write the output(s) to. */
@property(nonatomic, readwrite, strong, null_resettable) GCVNGcsDestination *gcsDestination;
/** Test to see if @c gcsDestination has been set. */
@property(nonatomic, readwrite) BOOL hasGcsDestination;

/**
 * The max number of response protos to put into each output JSON file on
 * Google Cloud Storage.
 * The valid range is [1, 100]. If not specified, the default value is 20.
 *
 * For example, for one pdf file with 100 pages, 100 response protos will
 * be generated. If `batch_size` = 20, then 5 json files each
 * containing 20 response protos will be written under the prefix
 * `gcs_destination`.`uri`.
 *
 * Currently, batch_size only applies to GcsDestination, with potential future
 * support for other output configurations.
 **/
@property(nonatomic, readwrite) int32_t batchSize;

@end

#pragma mark - GCVNGcsSource

typedef GPB_ENUM(GCVNGcsSource_FieldNumber) {
  GCVNGcsSource_FieldNumber_Uri = 1,
};

/**
 * The Google Cloud Storage location where the input will be read from.
 **/
@interface GCVNGcsSource : GPBMessage

/**
 * Google Cloud Storage URI for the input file. This must only be a
 * Google Cloud Storage object. Wildcards are not currently supported.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *uri;

@end

#pragma mark - GCVNGcsDestination

typedef GPB_ENUM(GCVNGcsDestination_FieldNumber) {
  GCVNGcsDestination_FieldNumber_Uri = 1,
};

/**
 * The Google Cloud Storage location where the output will be written to.
 **/
@interface GCVNGcsDestination : GPBMessage

/**
 * Google Cloud Storage URI where the results will be stored. Results will
 * be in JSON format and preceded by its corresponding input URI. This field
 * can either represent a single file, or a prefix for multiple outputs.
 * Prefixes must end in a `/`.
 *
 * Examples:
 *
 * *    File: gs://bucket-name/filename.json
 * *    Prefix: gs://bucket-name/prefix/here/
 * *    File: gs://bucket-name/prefix/here
 *
 * If multiple outputs, each response is still AnnotateFileResponse, each of
 * which contains some subset of the full list of AnnotateImageResponse.
 * Multiple outputs can happen if, for example, the output JSON is too large
 * and overflows into multiple sharded files.
 **/
@property(nonatomic, readwrite, copy, null_resettable) NSString *uri;

@end

#pragma mark - GCVNOperationMetadata

typedef GPB_ENUM(GCVNOperationMetadata_FieldNumber) {
  GCVNOperationMetadata_FieldNumber_State = 1,
  GCVNOperationMetadata_FieldNumber_CreateTime = 5,
  GCVNOperationMetadata_FieldNumber_UpdateTime = 6,
};

/**
 * Contains metadata for the BatchAnnotateImages operation.
 **/
@interface GCVNOperationMetadata : GPBMessage

/** Current state of the batch operation. */
@property(nonatomic, readwrite) GCVNOperationMetadata_State state;

/** The time when the batch request was received. */
@property(nonatomic, readwrite, strong, null_resettable) GPBTimestamp *createTime;
/** Test to see if @c createTime has been set. */
@property(nonatomic, readwrite) BOOL hasCreateTime;

/** The time when the operation result was last updated. */
@property(nonatomic, readwrite, strong, null_resettable) GPBTimestamp *updateTime;
/** Test to see if @c updateTime has been set. */
@property(nonatomic, readwrite) BOOL hasUpdateTime;

@end

/**
 * Fetches the raw value of a @c GCVNOperationMetadata's @c state property, even
 * if the value was not defined by the enum at the time the code was generated.
 **/
int32_t GCVNOperationMetadata_State_RawValue(GCVNOperationMetadata *message);
/**
 * Sets the raw value of an @c GCVNOperationMetadata's @c state property, allowing
 * it to be set to a value that was not defined by the enum at the time the code
 * was generated.
 **/
void SetGCVNOperationMetadata_State_RawValue(GCVNOperationMetadata *message, int32_t value);

NS_ASSUME_NONNULL_END

CF_EXTERN_C_END

#pragma clang diagnostic pop

// @@protoc_insertion_point(global_scope)
